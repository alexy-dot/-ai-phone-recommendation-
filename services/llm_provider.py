#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMæœåŠ¡æä¾›è€…
é›†æˆå¤§è¯­è¨€æ¨¡å‹APIï¼Œæä¾›æ™ºèƒ½å¯¹è¯å’Œéœ€æ±‚ç†è§£èƒ½åŠ›
æ”¯æŒGeminiã€Kimiå’ŒArk API
"""

import os
import json
import requests
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

@dataclass
class LLMConfig:
    """LLMé…ç½®"""
    api_key: str
    model_name: str = "gemini-pro"
    base_url: str = "https://generativelanguage.googleapis.com/v1beta/models"
    max_tokens: int = 1000
    temperature: float = 0.7
    api_type: str = "gemini"  # gemini, kimi, ark

class LLMProvider:
    """LLMæœåŠ¡æä¾›è€…"""
    
    def __init__(self, config: Optional[LLMConfig] = None):
        self.config = config or self._load_default_config()
        self.conversation_history: List[Dict] = []
    
    def _load_default_config(self) -> LLMConfig:
        """åŠ è½½é»˜è®¤é…ç½®"""
        # é¦–å…ˆå°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
        config_file = "config.json"
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
                print(f"ğŸ“‹ é…ç½®å†…å®¹: {config_data}")
                
                # æ£€æŸ¥APIç±»å‹
                if 'ARK_API_KEY' in config_data:
                    print("ğŸ”§ æ£€æµ‹åˆ°Ark APIé…ç½®")
                    # Ark APIé…ç½®
                    config = LLMConfig(
                        api_key=config_data.get('ARK_API_KEY', ''),
                        model_name=config_data.get('LLM_MODEL_NAME', 'doubao-seed-1-6-250615'),
                        base_url=config_data.get('LLM_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3'),
                        max_tokens=config_data.get('max_tokens', 1000),
                        temperature=config_data.get('temperature', 0.7),
                        api_type="ark"
                    )
                elif config_data.get('LLM_MODEL_NAME', '').startswith('kimi'):
                    print("ğŸ”§ æ£€æµ‹åˆ°Kimi APIé…ç½®")
                    # Kimi APIé…ç½®
                    config = LLMConfig(
                        api_key=config_data.get('GEMINI_API_KEY', ''),
                        model_name=config_data.get('LLM_MODEL_NAME', 'kimi-k2-250711'),
                        base_url="https://kimi.moonshot.cn/api/chat",
                        max_tokens=config_data.get('max_tokens', 1000),
                        temperature=config_data.get('temperature', 0.7),
                        api_type="kimi"
                    )
                else:
                    print("ğŸ”§ æ£€æµ‹åˆ°Gemini APIé…ç½®")
                    # Gemini APIé…ç½®
                    config = LLMConfig(
                        api_key=config_data.get('GEMINI_API_KEY', ''),
                        model_name=config_data.get('LLM_MODEL_NAME', 'gemini-pro'),
                        base_url=config_data.get('base_url', 'https://generativelanguage.googleapis.com/v1beta/models'),
                        max_tokens=config_data.get('max_tokens', 1000),
                        temperature=config_data.get('temperature', 0.7),
                        api_type="gemini"
                    )
                
                print(f"ğŸ”‘ APIå¯†é’¥é•¿åº¦: {len(config.api_key)} å­—ç¬¦")
                print(f"ğŸ¤– æ¨¡å‹åç§°: {config.model_name}")
                print(f"ğŸŒ APIåœ°å€: {config.base_url}")
                print(f"ğŸ“¡ APIç±»å‹: {config.api_type}")
                return config
            except Exception as e:
                print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œå°è¯•ç¯å¢ƒå˜é‡
        api_key = os.getenv('ARK_API_KEY') or os.getenv('GEMINI_API_KEY', '')
        if not api_key:
            print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ï¼ŒLLMåŠŸèƒ½å°†ä¸å¯ç”¨")
        else:
            print("ğŸ”§ ä»ç¯å¢ƒå˜é‡åŠ è½½APIå¯†é’¥")
        
        return LLMConfig(api_key=api_key)
    
    def _make_api_request(self, prompt: str, context: str = "") -> Optional[str]:
        """å‘é€APIè¯·æ±‚"""
        if not self.config.api_key:
            return None
        
        try:
            # æ ¹æ®APIç±»å‹é€‰æ‹©è¯·æ±‚æ–¹æ³•
            if self.config.api_type == "ark":
                return self._make_ark_request(prompt, context)
            elif self.config.api_type == "kimi":
                return self._make_kimi_request(prompt, context)
            else:
                return self._make_gemini_request(prompt, context)
        except Exception as e:
            print(f"LLM APIè¯·æ±‚å¤±è´¥: {e}")
            return None

    def _make_ark_request(self, prompt: str, context: str = "") -> Optional[str]:
        """å‘é€Ark APIè¯·æ±‚ - ä½¿ç”¨æ­£ç¡®çš„APIè°ƒç”¨æ–¹å¼"""
        try:
            from openai import OpenAI
            
            # åˆå§‹åŒ–Arkå®¢æˆ·ç«¯
            client = OpenAI(
                base_url=self.config.base_url,
                api_key=self.config.api_key,
                timeout=60.0
            )
            
            # æ„å»ºæ¶ˆæ¯
            messages = []
            if context:
                messages.append({"role": "system", "content": context})
            messages.append({"role": "user", "content": prompt})
            
            print(f"æ­£åœ¨å‘é€Ark APIè¯·æ±‚åˆ°: {self.config.base_url}")
            print(f"ä½¿ç”¨æ¨¡å‹: {self.config.model_name}")
            
            # å‘é€è¯·æ±‚
            completion = client.chat.completions.create(
                model=self.config.model_name,
                messages=messages,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens
            )
            
            print(f"APIè¯·æ±‚æˆåŠŸ")
            
            # è¿”å›å“åº”å†…å®¹
            if completion.choices and completion.choices[0].message:
                return completion.choices[0].message.content
            
            return None
            
        except Exception as e:
            print(f"Ark APIè¯·æ±‚å¤±è´¥: {e}")
            return None

    def _make_kimi_request(self, prompt: str, context: str = "") -> Optional[str]:
        """å‘é€Kimi APIè¯·æ±‚"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.config.api_key}"
            }
            
            data = {
                "messages": [
                    {"role": "user", "content": f"{context}\n\n{prompt}"}
                ],
                "model": self.config.model_name,
                "temperature": self.config.temperature,
                "max_tokens": self.config.max_tokens,
                "stream": False  # æ·»åŠ streamå‚æ•°
            }
            
            print(f"æ­£åœ¨å‘é€Kimi APIè¯·æ±‚åˆ°: {self.config.base_url}")
            print(f"ä½¿ç”¨æ¨¡å‹: {self.config.model_name}")
            
            response = requests.post(
                self.config.base_url,
                headers=headers,
                json=data,
                timeout=60,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’
                verify=True  # ç¡®ä¿SSLéªŒè¯
            )
            
            print(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"APIå“åº”å†…å®¹: {result}")
                if 'choices' in result and result['choices']:
                    return result['choices'][0]['message']['content']
                else:
                    print(f"APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
            else:
                print(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            
            return None
            
        except requests.exceptions.Timeout:
            print("Kimi APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return None
        except requests.exceptions.ConnectionError:
            print("æ— æ³•è¿æ¥åˆ°Kimi APIæœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return None
        except requests.exceptions.RequestException as e:
            print(f"Kimi APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None
        except Exception as e:
            print(f"Kimi APIè¯·æ±‚æœªçŸ¥é”™è¯¯: {e}")
            return None

    def _make_gemini_request(self, prompt: str, context: str = "") -> Optional[str]:
        """å‘é€Gemini APIè¯·æ±‚"""
        url = f"{self.config.base_url}/{self.config.model_name}:generateContent"
        
        headers = {
            "Content-Type": "application/json",
        }
        
        full_prompt = f"{context}\n\nç”¨æˆ·: {prompt}\n\nåŠ©æ‰‹:"
        
        data = {
            "contents": [{
                "parts": [{"text": full_prompt}]
            }],
            "generationConfig": {
                "temperature": self.config.temperature,
                "maxOutputTokens": self.config.max_tokens,
            }
        }
        
        response = requests.post(
            url,
            headers=headers,
            params={"key": self.config.api_key},
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and result['candidates']:
                return result['candidates'][0]['content']['parts'][0]['text']
        
        return None
    
    def understand_intent(self, user_input: str, context: str = "") -> Dict[str, Any]:
        """ç†è§£ç”¨æˆ·æ„å›¾"""
        # é¦–å…ˆå°è¯•LLM API
        if self.is_available():
            prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„æ„å›¾å’Œå…³é”®ä¿¡æ¯ï¼Œè¿”å›JSONæ ¼å¼çš„ç»“æœï¼š

ç”¨æˆ·è¾“å…¥: {user_input}

è¯·è¿”å›åŒ…å«ä»¥ä¸‹å­—æ®µçš„JSON:
{{
    "intent": "æŸ¥è¯¢|æ¯”è¾ƒ|æ¾„æ¸…|é—²èŠ",
    "budget_min": æ•°å­—æˆ–null,
    "budget_max": æ•°å­—æˆ–null,
    "preferences": ["åå¥½1", "åå¥½2"],
    "priority": "æ€§èƒ½|æ‹ç…§|ç»­èˆª|ä¾¿æº|ä»·æ ¼|å¤–è§‚",
    "clarification_needed": true/false,
    "confidence": 0.0-1.0
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
            
            response = self._make_api_request(prompt, context)
            if response and response.strip():  # ç¡®ä¿responseä¸ä¸ºNoneä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²
                try:
                    return json.loads(response.strip())
                except json.JSONDecodeError:
                    print(f"JSONè§£æå¤±è´¥ï¼Œå“åº”å†…å®¹: {response}")
                    pass
        
        # å¦‚æœLLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å›é€€
        print("ğŸ”„ ä½¿ç”¨æœ¬åœ°æ„å›¾ç†è§£å¼•æ“")
        return self.get_fallback_response("understand_intent", user_input=user_input)
    
    def generate_clarification_question(self, unclear_aspect: str, context: str = "", conversation_history: List[Dict] = None) -> str:
        """ç”Ÿæˆæ™ºèƒ½æ¾„æ¸…é—®é¢˜"""
        # é¦–å…ˆå°è¯•LLM API
        if self.is_available():
            # æ„å»ºæ›´æ™ºèƒ½çš„æç¤ºè¯
            history_context = ""
            if conversation_history:
                recent_messages = conversation_history[-3:]  # æœ€è¿‘3æ¡æ¶ˆæ¯
                history_context = "\n".join([f"ç”¨æˆ·: {msg.get('user', '')}" for msg in recent_messages])
            
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‰‹æœºå¯¼è´­åŠ©æ‰‹ã€‚ç”¨æˆ·çš„éœ€æ±‚ä¸­"{unclear_aspect}"æ–¹é¢ä¸å¤Ÿæ˜ç¡®ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªè‡ªç„¶ã€å‹å¥½ã€ä¸ªæ€§åŒ–çš„æ¾„æ¸…é—®é¢˜ã€‚

å¯¹è¯å†å²:
{history_context}

å½“å‰ä¸Šä¸‹æ–‡: {context}

è¦æ±‚:
1. é—®é¢˜è¦è‡ªç„¶ã€å‹å¥½ï¼ŒåƒçœŸäººå¯¼è´­ä¸€æ ·
2. é¿å…é‡å¤ä¹‹å‰é—®è¿‡çš„é—®é¢˜
3. æ ¹æ®å¯¹è¯å†å²è°ƒæ•´é—®é¢˜é£æ ¼
4. é—®é¢˜è¦å…·ä½“ã€æœ‰é’ˆå¯¹æ€§
5. å¯ä»¥ç»“åˆç”¨æˆ·ä¹‹å‰æåˆ°çš„å…¶ä»–ä¿¡æ¯

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´ã€è‡ªç„¶çš„æ¾„æ¸…é—®é¢˜ï¼Œç›´æ¥è¿”å›é—®é¢˜å†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
            
            response = self._make_api_request(prompt)
            if response and response.strip():  # ç¡®ä¿responseä¸ä¸ºNoneä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²
                return response.strip()
        
        # å¦‚æœLLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½æœ¬åœ°å›é€€
        print("ğŸ”„ ä½¿ç”¨æ™ºèƒ½æœ¬åœ°æ¾„æ¸…é—®é¢˜ç”Ÿæˆ")
        return self._smart_fallback_clarification_question(unclear_aspect, context, conversation_history)
    
    def _smart_fallback_clarification_question(self, unclear_aspect: str, context: str = "", conversation_history: List[Dict] = None) -> str:
        """æ™ºèƒ½æœ¬åœ°æ¾„æ¸…é—®é¢˜å›é€€"""
        import random
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»é—®è¿‡ç±»ä¼¼é—®é¢˜
        asked_questions = []
        if conversation_history:
            for msg in conversation_history:
                if 'system' in msg and 'æ¾„æ¸…' in str(msg.get('system', '')):
                    asked_questions.append(str(msg.get('system', '')))
        
        # æ ¹æ®ä¸åŒçš„ä¸æ¸…æ¥šæ–¹é¢ç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜
        question_templates = {
            "budget": [
                "æ‚¨çš„é¢„ç®—å¤§æ¦‚æ˜¯å¤šå°‘å‘¢ï¼Ÿ",
                "è¯·é—®æ‚¨èƒ½æ¥å—çš„ä»·æ ¼èŒƒå›´æ˜¯ï¼Ÿ",
                "æ‚¨å¸Œæœ›è´­ä¹°ä»€ä¹ˆä»·ä½çš„æ‰‹æœºï¼Ÿ",
                "ä»·æ ¼æ–¹é¢æ‚¨æœ‰ä»€ä¹ˆè€ƒè™‘å—ï¼Ÿ",
                "æ‚¨è§‰å¾—ä»€ä¹ˆä»·ä½çš„æ‰‹æœºæ¯”è¾ƒåˆé€‚ï¼Ÿ",
                "æ‚¨èƒ½å‘Šè¯‰æˆ‘å¤§æ¦‚çš„é¢„ç®—èŒƒå›´å—ï¼Ÿ",
                "ä»·æ ¼å¯¹æ‚¨æ¥è¯´é‡è¦å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ§åˆ¶åœ¨ä»€ä¹ˆä»·æ ¼åŒºé—´ï¼Ÿ"
            ],
            "performance": [
                "æ‚¨ä¸»è¦ç”¨æ‰‹æœºåšä»€ä¹ˆå‘¢ï¼Ÿæ¸¸æˆã€å·¥ä½œè¿˜æ˜¯æ—¥å¸¸ä½¿ç”¨ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºæ€§èƒ½æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚å—ï¼Ÿ",
                "æ‚¨ä¼šç©å¤§å‹æ¸¸æˆå—ï¼Ÿ",
                "å¹³æ—¶ä½¿ç”¨æ‰‹æœºä¸»è¦æ˜¯å“ªäº›åœºæ™¯ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºè¿è¡Œé€Ÿåº¦æ€ä¹ˆæ ·ï¼Ÿ",
                "æ‚¨éœ€è¦å¤„ç†å¤æ‚çš„ä»»åŠ¡å—ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºæµç•…åº¦æœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ",
                "æ‚¨ä¼šåŒæ—¶è¿è¡Œå¤šä¸ªåº”ç”¨å—ï¼Ÿ"
            ],
            "camera": [
                "æ‚¨æ›´æ³¨é‡å¤œæ™¯æ‹æ‘„è¿˜æ˜¯å¹¿è§’æ‹æ‘„ï¼Ÿ",
                "æ‹ç…§æ–¹é¢ï¼Œæ‚¨æ›´çœ‹é‡å“ªä¸ªåŠŸèƒ½ï¼Ÿ",
                "æ‚¨ä¸»è¦ç”¨æ‰‹æœºæ‹ä»€ä¹ˆç±»å‹çš„ç…§ç‰‡ï¼Ÿ",
                "æ‚¨å¯¹æ‹ç…§æœ‰ä»€ä¹ˆç‰¹æ®Šéœ€æ±‚å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºæ‹ç…§æ•ˆæœæ€ä¹ˆæ ·ï¼Ÿ",
                "æ‚¨ç»å¸¸æ‹ç…§å—ï¼Ÿ",
                "æ‚¨å¯¹ç›¸æœºåŠŸèƒ½æœ‰ä»€ä¹ˆåå¥½å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‹å‡ºä»€ä¹ˆæ ·çš„ç…§ç‰‡ï¼Ÿ"
            ],
            "battery": [
                "æ‚¨å¯¹ç»­èˆªæœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºèƒ½ç”¨å¤šä¹…ï¼Ÿ",
                "å¿«å……åŠŸèƒ½å¯¹æ‚¨é‡è¦å—ï¼Ÿ",
                "æ‚¨å¹³æ—¶ä½¿ç”¨æ‰‹æœºçš„æ—¶é—´é•¿å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›ç”µæ± ç»­èˆªæ€ä¹ˆæ ·ï¼Ÿ",
                "æ‚¨ç»å¸¸å¤–å‡ºå—ï¼Ÿ",
                "æ‚¨å¯¹å……ç”µé€Ÿåº¦æœ‰è¦æ±‚å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›å¤šä¹…å……ä¸€æ¬¡ç”µï¼Ÿ"
            ],
            "portability": [
                "æ‚¨æ›´åå¥½å¤§å±è¿˜æ˜¯å°å±æ‰‹æœºï¼Ÿ",
                "ä¾¿æºæ€§å¯¹æ‚¨æ¥è¯´é‡è¦å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºè½»ä¾¿ä¸€äº›è¿˜æ˜¯åŠŸèƒ½æ›´å…¨é¢ï¼Ÿ",
                "æ‚¨å¹³æ—¶ä¼šæŠŠæ‰‹æœºæ”¾åœ¨å“ªé‡Œï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºå°ºå¯¸æœ‰ä»€ä¹ˆåå¥½å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºå®¹æ˜“æºå¸¦å—ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºé‡é‡æœ‰è¦æ±‚å—ï¼Ÿ",
                "æ‚¨å–œæ¬¢å•æ‰‹æ“ä½œå—ï¼Ÿ"
            ],
            "appearance": [
                "æ‚¨å¯¹å¤–è§‚æœ‰ä»€ä¹ˆåå¥½å—ï¼Ÿ",
                "æ‚¨å–œæ¬¢ä»€ä¹ˆé¢œè‰²çš„æ‰‹æœºï¼Ÿ",
                "æ‚¨æ›´çœ‹é‡æ‰‹æœºçš„è®¾è®¡è¿˜æ˜¯åŠŸèƒ½ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºå¤–è§‚æœ‰ä»€ä¹ˆè¦æ±‚å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºçœ‹èµ·æ¥æ€ä¹ˆæ ·ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºæè´¨æœ‰åå¥½å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºæ—¶å°šä¸€äº›å—ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºé€ å‹æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Ÿ"
            ],
            "brand": [
                "æ‚¨å¯¹å“ç‰Œæœ‰ä»€ä¹ˆåå¥½å—ï¼Ÿ",
                "æ‚¨æ›´å€¾å‘äºå“ªä¸ªå“ç‰Œçš„æ‰‹æœºï¼Ÿ",
                "æ‚¨æœ‰ä»€ä¹ˆå“ç‰Œåå¥½æˆ–å¿Œè®³å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›è´­ä¹°ä»€ä¹ˆå“ç‰Œçš„æ‰‹æœºï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºå“ç‰Œæœ‰ä»€ä¹ˆè€ƒè™‘å—ï¼Ÿ",
                "æ‚¨æœ‰å–œæ¬¢çš„æ‰‹æœºå“ç‰Œå—ï¼Ÿ",
                "æ‚¨å¯¹æŸäº›å“ç‰Œæœ‰åè§å—ï¼Ÿ",
                "æ‚¨å¸Œæœ›å°è¯•æ–°å“ç‰Œå—ï¼Ÿ"
            ],
            "usage_scenario": [
                "æ‚¨ä¸»è¦ç”¨æ‰‹æœºåšä»€ä¹ˆå‘¢ï¼Ÿ",
                "æ‚¨å¹³æ—¶ä½¿ç”¨æ‰‹æœºçš„åœºæ™¯æœ‰å“ªäº›ï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºèƒ½æ»¡è¶³å“ªäº›éœ€æ±‚ï¼Ÿ",
                "æ‚¨ä½¿ç”¨æ‰‹æœºçš„ä¸»è¦ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºåœ¨å“ªäº›æ–¹é¢è¡¨ç°çªå‡ºï¼Ÿ",
                "æ‚¨çš„ç”Ÿæ´»ä¸­å“ªäº›åœºæ™¯éœ€è¦ç”¨åˆ°æ‰‹æœºï¼Ÿ",
                "æ‚¨å¸Œæœ›æ‰‹æœºæˆä¸ºä»€ä¹ˆæ ·çš„å·¥å…·ï¼Ÿ",
                "æ‚¨å¯¹æ‰‹æœºæœ‰ä»€ä¹ˆæœŸå¾…ï¼Ÿ"
            ]
        }
        
        # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´é—®é¢˜ç±»å‹
        if unclear_aspect == "general_preference":
            # å¦‚æœæ˜¯ä¸€èˆ¬åå¥½ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æœ€åˆé€‚çš„é—®é¢˜ç±»å‹
            if "æ‹ç…§" in context or "ç›¸æœº" in context:
                unclear_aspect = "camera"
            elif "æ¸¸æˆ" in context or "æ€§èƒ½" in context:
                unclear_aspect = "performance"
            elif "ç»­èˆª" in context or "ç”µæ± " in context:
                unclear_aspect = "battery"
            elif "è½»ä¾¿" in context or "å¤§å±" in context:
                unclear_aspect = "portability"
            else:
                unclear_aspect = "usage_scenario"
        
        # è·å–é—®é¢˜æ¨¡æ¿
        templates = question_templates.get(unclear_aspect, question_templates["usage_scenario"])
        
        # é¿å…é‡å¤é—®é¢˜
        available_questions = [q for q in templates if not any(q in asked for asked in asked_questions)]
        
        if not available_questions:
            # å¦‚æœæ‰€æœ‰æ¨¡æ¿éƒ½ç”¨è¿‡äº†ï¼Œç”Ÿæˆä¸€ä¸ªé€šç”¨ä½†ä¸ªæ€§åŒ–çš„é—®é¢˜
            return f"å…³äº{unclear_aspect}æ–¹é¢ï¼Œæ‚¨è¿˜æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚å—ï¼Ÿ"
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªæœªé—®è¿‡çš„é—®é¢˜
        return random.choice(available_questions)
    
    def generate_recommendation_explanation(self, phone_name: str, reasons: List[str], 
                                         user_demand: str) -> str:
        """ç”Ÿæˆæ¨èè§£é‡Š"""
        # é¦–å…ˆå°è¯•LLM API
        if self.is_available():
            prompt = f"""
è¯·ä¸ºä»¥ä¸‹æ‰‹æœºæ¨èç”Ÿæˆä¸€ä¸ªè‡ªç„¶ã€è¯¦ç»†çš„è§£é‡Šï¼š

æ‰‹æœº: {phone_name}
æ¨èç†ç”±: {', '.join(reasons)}
ç”¨æˆ·éœ€æ±‚: {user_demand}

è¯·ç”Ÿæˆä¸€æ®µè‡ªç„¶çš„æ¨èè§£é‡Šï¼Œè¯´æ˜ä¸ºä»€ä¹ˆè¿™æ¬¾æ‰‹æœºé€‚åˆç”¨æˆ·çš„éœ€æ±‚ã€‚
"""
            
            response = self._make_api_request(prompt)
            if response and response.strip():  # ç¡®ä¿responseä¸ä¸ºNoneä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²
                return response.strip()
        
        # å¦‚æœLLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å›é€€
        print("ğŸ”„ ä½¿ç”¨æœ¬åœ°æ¨èè§£é‡Šç”Ÿæˆ")
        return self.get_fallback_response("generate_recommendation_explanation", 
                                        phone_name=phone_name, reasons=reasons, user_demand=user_demand)
    
    def generate_comparison_report(self, phones: List[Dict], user_demand: str) -> str:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        # é¦–å…ˆå°è¯•LLM API
        if self.is_available():
            phone_info = "\n".join([
                f"- {phone['name']}: Â¥{phone['price']}, {phone['cpu']}, {phone['camera_mp']}MP"
                for phone in phones
            ])
            
            prompt = f"""
è¯·ä¸ºä»¥ä¸‹æ‰‹æœºç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„å¯¹æ¯”åˆ†ææŠ¥å‘Šï¼š

ç”¨æˆ·éœ€æ±‚: {user_demand}

å¯¹æ¯”æ‰‹æœº:
{phone_info}

è¯·ä»æ€§èƒ½ã€æ‹ç…§ã€ç»­èˆªã€ä¾¿æºæ€§ã€ä»·æ ¼ç­‰æ–¹é¢è¿›è¡Œè¯¦ç»†å¯¹æ¯”åˆ†æï¼Œç»™å‡ºè´­ä¹°å»ºè®®ã€‚
"""
            
            response = self._make_api_request(prompt)
            if response and response.strip():  # ç¡®ä¿responseä¸ä¸ºNoneä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²
                return response.strip()
        
        # å¦‚æœLLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å›é€€
        print("ğŸ”„ ä½¿ç”¨æœ¬åœ°å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆ")
        return self.get_fallback_response("generate_comparison_report", phones=phones, user_demand=user_demand)
    
    def is_available(self) -> bool:
        """æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦å¯ç”¨"""
        if not self.config.api_key:
            return False
        
        # å¯¹äºArk APIï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›Trueï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æµ‹è¯•è¿‡å®ƒå¯ä»¥å·¥ä½œ
        if self.config.api_type == "ark":
            return True
        
        # å°è¯•ç®€å•çš„ç½‘ç»œè¿æ¥æµ‹è¯•
        try:
            if self.config.api_type == "kimi":
                response = requests.get(self.config.base_url, timeout=5)
            else:
                response = requests.get("https://generativelanguage.googleapis.com", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_fallback_response(self, method: str, **kwargs) -> Any:
        """è·å–æœ¬åœ°å›é€€å“åº”"""
        if method == "understand_intent":
            return self._fallback_understand_intent(kwargs.get('user_input', ''))
        elif method == "generate_clarification_question":
            return self._fallback_clarification_question(kwargs.get('unclear_aspect', ''))
        elif method == "generate_recommendation_explanation":
            return self._fallback_recommendation_explanation(
                kwargs.get('phone_name', ''),
                kwargs.get('reasons', []),
                kwargs.get('user_demand', '')
            )
        elif method == "generate_comparison_report":
            return self._fallback_comparison_report(
                kwargs.get('phones', []),
                kwargs.get('user_demand', '')
            )
        return None
    
    def _fallback_understand_intent(self, user_input: str) -> Dict[str, Any]:
        """æœ¬åœ°æ„å›¾ç†è§£å›é€€"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        user_input_lower = user_input.lower()
        
        # é¢„ç®—æå–
        budget_min = None
        budget_max = None
        if 'é¢„ç®—' in user_input or 'ä»·æ ¼' in user_input:
            import re
            # åŒ¹é…æ•°å­—èŒƒå›´
            budget_patterns = [
                r'(\d+)-(\d+)',  # 3000-4000
                r'(\d+)åˆ°(\d+)',  # 3000åˆ°4000
                r'(\d+)ä»¥ä¸‹',     # 4000ä»¥ä¸‹
                r'(\d+)ä»¥å†…',     # 4000ä»¥å†…
                r'(\d+)ä»¥ä¸Š',     # 3000ä»¥ä¸Š
            ]
            
            for pattern in budget_patterns:
                matches = re.findall(pattern, user_input)
                if matches:
                    if len(matches[0]) == 2:
                        budget_min = int(matches[0][0])
                        budget_max = int(matches[0][1])
                    else:
                        if 'ä»¥ä¸‹' in user_input or 'ä»¥å†…' in user_input:
                            budget_max = int(matches[0])
                        elif 'ä»¥ä¸Š' in user_input:
                            budget_min = int(matches[0])
                    break
        
        # åå¥½æå–
        preferences = []
        preference_keywords = {
            'æ‹ç…§': ['æ‹ç…§', 'ç›¸æœº', 'æ‘„åƒ', 'æ‘„å½±'],
            'æ€§èƒ½': ['æ€§èƒ½', 'æ¸¸æˆ', 'å¤„ç†å™¨', 'cpu', 'å‘çƒ­'],
            'ç»­èˆª': ['ç»­èˆª', 'ç”µæ± ', 'å……ç”µ'],
            'ä¾¿æº': ['ä¾¿æº', 'è½»ä¾¿', 'é‡é‡', 'å°ºå¯¸'],
            'å¤–è§‚': ['å¤–è§‚', 'é¢œå€¼', 'è®¾è®¡', 'é¢œè‰²']
        }
        
        for category, keywords in preference_keywords.items():
            if any(keyword in user_input_lower for keyword in keywords):
                preferences.append(category)
        
        # ä¼˜å…ˆçº§åˆ¤æ–­
        priority = None
        if preferences:
            priority = preferences[0]
        
        return {
            "intent": "æŸ¥è¯¢",
            "budget_min": budget_min,
            "budget_max": budget_max,
            "preferences": preferences,
            "priority": priority,
            "clarification_needed": len(preferences) < 2 or (budget_min is None and budget_max is None),
            "confidence": 0.7
        }
    
    def _fallback_clarification_question(self, unclear_aspect: str) -> str:
        """æœ¬åœ°æ¾„æ¸…é—®é¢˜å›é€€"""
        questions = {
            "budget": "æ‚¨çš„é¢„ç®—å¤§æ¦‚æ˜¯å¤šå°‘å‘¢ï¼Ÿ",
            "performance": "æ‚¨å¯¹æ‰‹æœºæ€§èƒ½æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚å—ï¼Ÿ",
            "camera": "æ‚¨æ›´æ³¨é‡å¤œæ™¯æ‹æ‘„è¿˜æ˜¯å¹¿è§’æ‹æ‘„ï¼Ÿ",
            "battery": "æ‚¨å¯¹ç»­èˆªæœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ",
            "portability": "æ‚¨æ›´åå¥½å¤§å±è¿˜æ˜¯å°å±æ‰‹æœºï¼Ÿ",
            "appearance": "æ‚¨å¯¹å¤–è§‚æœ‰ä»€ä¹ˆåå¥½å—ï¼Ÿ"
        }
        return questions.get(unclear_aspect, "èƒ½è¯¦ç»†è¯´æ˜ä¸€ä¸‹æ‚¨çš„éœ€æ±‚å—ï¼Ÿ")
    
    def _fallback_recommendation_explanation(self, phone_name: str, reasons: List[str], user_demand: str) -> str:
        """æœ¬åœ°æ¨èè§£é‡Šå›é€€"""
        return f"æˆ‘æ¨è{phone_name}ï¼Œå› ä¸º{', '.join(reasons)}ã€‚è¿™æ¬¾æ‰‹æœºåº”è¯¥èƒ½æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚"
    
    def _fallback_comparison_report(self, phones: List[Dict], user_demand: str) -> str:
        """æœ¬åœ°å¯¹æ¯”æŠ¥å‘Šå›é€€"""
        if not phones:
            return "æš‚æ— å¯¹æ¯”æ•°æ®"
        
        report = f"åŸºäºæ‚¨çš„éœ€æ±‚'{user_demand}'ï¼Œæˆ‘ä¸ºæ‚¨å¯¹æ¯”äº†{len(phones)}æ¬¾æ‰‹æœºï¼š\n\n"
        
        for i, phone in enumerate(phones, 1):
            report += f"{i}. {phone.get('name', 'æœªçŸ¥å‹å·')}\n"
            report += f"   ä»·æ ¼: Â¥{phone.get('price', 'æœªçŸ¥')}\n"
            report += f"   å¤„ç†å™¨: {phone.get('cpu', 'æœªçŸ¥')}\n"
            report += f"   æ‘„åƒå¤´: {phone.get('camera_mp', 'æœªçŸ¥')}MP\n"
            if 'battery_mah' in phone:
                report += f"   ç”µæ± : {phone['battery_mah']}mAh\n"
            report += "\n"
        
        report += "å»ºè®®æ‚¨æ ¹æ®é¢„ç®—å’Œå…·ä½“éœ€æ±‚é€‰æ‹©æœ€é€‚åˆçš„æœºå‹ã€‚"
        return report 